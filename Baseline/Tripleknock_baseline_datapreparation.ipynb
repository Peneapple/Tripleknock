{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c74a44e-0b82-43db-b140-698e9e78085f",
   "metadata": {},
   "source": [
    "## Part-1 First we get the essential gene simulated by FBA with same threshold 90% growth reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10af06c-aed5-480f-b1ce-d696f4f0178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e82e0d-b13e-4649-af05-28c8a83f66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential genes (label==1): n=196\n",
      "['b0003', 'b0004', 'b0025', 'b0029', 'b0031', 'b0052', 'b0054', 'b0071', 'b0072', 'b0074', 'b0084', 'b0085', 'b0086', 'b0087', 'b0088', 'b0089', 'b0090', 'b0091', 'b0096', 'b0103', 'b0109', 'b0131', 'b0133', 'b0134', 'b0142', 'b0154', 'b0159', 'b0166', 'b0173', 'b0174', 'b0175', 'b0179', 'b0180', 'b0181', 'b0182', 'b0185', 'b0242', 'b0243', 'b0369', 'b0386', 'b0414', 'b0415', 'b0417', 'b0420', 'b0421', 'b0423', 'b0522', 'b0523', 'b0524', 'b0635', 'b0639', 'b0641', 'b0720', 'b0750', 'b0774', 'b0775', 'b0776', 'b0777', 'b0778', 'b0908', 'b0914', 'b0915', 'b0918', 'b1062', 'b1069', 'b1091', 'b1092', 'b1093', 'b1094', 'b1098', 'b1131', 'b1136', 'b1208', 'b1210', 'b1215', 'b1260', 'b1261', 'b1262', 'b1263', 'b1264', 'b1277', 'b1281', 'b1288', 'b1662', 'b1693', 'b1740', 'b1812', 'b2019', 'b2020', 'b2021', 'b2022', 'b2023', 'b2024', 'b2025', 'b2026', 'b2103', 'b2153', 'b2312', 'b2315', 'b2316', 'b2323', 'b2329', 'b2400', 'b2472', 'b2476', 'b2478', 'b2499', 'b2507', 'b2515', 'b2530', 'b2557', 'b2564', 'b2574', 'b2585', 'b2599', 'b2600', 'b2615', 'b2687', 'b2746', 'b2747', 'b2750', 'b2751', 'b2752', 'b2762', 'b2763', 'b2764', 'b2780', 'b2818', 'b2827', 'b2838', 'b2942', 'b3018', 'b3040', 'b3041', 'b3058', 'b3172', 'b3176', 'b3177', 'b3187', 'b3189', 'b3196', 'b3198', 'b3199', 'b3200', 'b3201', 'b3255', 'b3256', 'b3360', 'b3368', 'b3389', 'b3412', 'b3433', 'b3607', 'b3633', 'b3634', 'b3639', 'b3642', 'b3648', 'b3729', 'b3730', 'b3770', 'b3771', 'b3774', 'b3804', 'b3805', 'b3809', 'b3843', 'b3850', 'b3870', 'b3939', 'b3941', 'b3957', 'b3958', 'b3959', 'b3960', 'b3967', 'b3972', 'b3974', 'b3990', 'b3991', 'b3992', 'b3993', 'b3994', 'b3997', 'b4005', 'b4006', 'b4013', 'b4040', 'b4160', 'b4177', 'b4214', 'b4245', 'b4261', 'b4262', 'b4407', 's0001']\n",
      "\n",
      "Loaded combos: shape=(576107619, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering rows:   3%|█▎                                      | 19716247/576107619 [20:08<9:03:25, 17064.14it/s]"
     ]
    }
   ],
   "source": [
    "# ========== Paths ==========\n",
    "essential_file = \"/data1/xpgeng/cross_pathogen/one_two_knockout/iML1515_1KO_growth\"\n",
    "combo_file = \"/data1/xpgeng/cross_pathogen/FBA/iML1515_all.csv\"\n",
    "out_file = \"/data1/xpgeng/cross_pathogen/FBA/non-essential.csv\"\n",
    "\n",
    "# ========== Step 1: Read essential genes (label==1) ==========\n",
    "essential_genes = []\n",
    "\n",
    "with open(essential_file, \"r\") as f:\n",
    "    next(f)  # skip header line\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = [p.strip() for p in line.split(\",\")]\n",
    "        # expected: gene, val1, val2, label\n",
    "        gene = parts[0]\n",
    "        label = parts[-1]\n",
    "\n",
    "        try:\n",
    "            if int(float(label)) == 1:\n",
    "                essential_genes.append(gene)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "essential_genes = sorted(set(essential_genes))\n",
    "essential_set = set(essential_genes)\n",
    "\n",
    "print(f\"Essential genes (label==1): n={len(essential_genes)}\")\n",
    "print(essential_genes)\n",
    "\n",
    "# ========== Step 2: Read combination CSV ==========\n",
    "df = pd.read_csv(combo_file, header=None)\n",
    "print(f\"\\nLoaded combos: shape={df.shape}\")\n",
    "\n",
    "# ========== Step 3: Filter rows that contain NO essential genes ==========\n",
    "keep_idx = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Filtering rows\"):\n",
    "    genes_in_row = set()\n",
    "\n",
    "    for x in row.values:\n",
    "        if pd.isna(x):\n",
    "            continue\n",
    "        s = str(x).strip()\n",
    "        if not s or s.lower() == \"nan\":\n",
    "            continue\n",
    "        genes_in_row.add(s)\n",
    "\n",
    "    # keep the row if it has zero overlap with essential genes\n",
    "    if genes_in_row.isdisjoint(essential_set):\n",
    "        keep_idx.append(idx)\n",
    "\n",
    "non_essential_df = df.loc[keep_idx].reset_index(drop=True)\n",
    "print(f\"Rows with NO essential genes: {len(non_essential_df)}\")\n",
    "\n",
    "# ========== Step 4: Write output ==========\n",
    "os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "non_essential_df.to_csv(out_file, header=False, index=False)\n",
    "print(f\"Saved: {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4109aebc-c85c-4973-b360-63af99c0fe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essential genes (label==1): n=196\n",
      "['b0003', 'b0004', 'b0025', 'b0029', 'b0031', 'b0052', 'b0054', 'b0071', 'b0072', 'b0074', 'b0084', 'b0085', 'b0086', 'b0087', 'b0088', 'b0089', 'b0090', 'b0091', 'b0096', 'b0103', 'b0109', 'b0131', 'b0133', 'b0134', 'b0142', 'b0154', 'b0159', 'b0166', 'b0173', 'b0174', 'b0175', 'b0179', 'b0180', 'b0181', 'b0182', 'b0185', 'b0242', 'b0243', 'b0369', 'b0386', 'b0414', 'b0415', 'b0417', 'b0420', 'b0421', 'b0423', 'b0522', 'b0523', 'b0524', 'b0635', 'b0639', 'b0641', 'b0720', 'b0750', 'b0774', 'b0775', 'b0776', 'b0777', 'b0778', 'b0908', 'b0914', 'b0915', 'b0918', 'b1062', 'b1069', 'b1091', 'b1092', 'b1093', 'b1094', 'b1098', 'b1131', 'b1136', 'b1208', 'b1210', 'b1215', 'b1260', 'b1261', 'b1262', 'b1263', 'b1264', 'b1277', 'b1281', 'b1288', 'b1662', 'b1693', 'b1740', 'b1812', 'b2019', 'b2020', 'b2021', 'b2022', 'b2023', 'b2024', 'b2025', 'b2026', 'b2103', 'b2153', 'b2312', 'b2315', 'b2316', 'b2323', 'b2329', 'b2400', 'b2472', 'b2476', 'b2478', 'b2499', 'b2507', 'b2515', 'b2530', 'b2557', 'b2564', 'b2574', 'b2585', 'b2599', 'b2600', 'b2615', 'b2687', 'b2746', 'b2747', 'b2750', 'b2751', 'b2752', 'b2762', 'b2763', 'b2764', 'b2780', 'b2818', 'b2827', 'b2838', 'b2942', 'b3018', 'b3040', 'b3041', 'b3058', 'b3172', 'b3176', 'b3177', 'b3187', 'b3189', 'b3196', 'b3198', 'b3199', 'b3200', 'b3201', 'b3255', 'b3256', 'b3360', 'b3368', 'b3389', 'b3412', 'b3433', 'b3607', 'b3633', 'b3634', 'b3639', 'b3642', 'b3648', 'b3729', 'b3730', 'b3770', 'b3771', 'b3774', 'b3804', 'b3805', 'b3809', 'b3843', 'b3850', 'b3870', 'b3939', 'b3941', 'b3957', 'b3958', 'b3959', 'b3960', 'b3967', 'b3972', 'b3974', 'b3990', 'b3991', 'b3992', 'b3993', 'b3994', 'b3997', 'b4005', 'b4006', 'b4013', 'b4040', 'b4160', 'b4177', 'b4214', 'b4245', 'b4261', 'b4262', 'b4407', 's0001']\n",
      "\n",
      "Loaded combos: shape=(576107619, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering rows: 100%|███████████████████████████████████████| 576107619/576107619 [8:45:05<00:00, 18285.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with essential genes: 195387920\n",
      "Saved: /data1/xpgeng/cross_pathogen/FBA/iML1515_all_with-essential.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== Paths ==========\n",
    "essential_file = \"/data1/xpgeng/cross_pathogen/one_two_knockout/iML1515_1KO_growth\"\n",
    "combo_file = \"/data1/xpgeng/cross_pathogen/FBA/iML1515_all.csv\"\n",
    "out_file = \"/data1/xpgeng/cross_pathogen/FBA/iML1515_all_with-essential.csv\"\n",
    "\n",
    "# ========== Step 1: Read essential genes (label==1) ==========\n",
    "essential_genes = []\n",
    "\n",
    "with open(essential_file, \"r\") as f:\n",
    "    next(f)  # skip header line\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = [p.strip() for p in line.split(\",\")]\n",
    "        # expected: gene, val1, val2, label\n",
    "        gene = parts[0]\n",
    "        label = parts[-1]\n",
    "\n",
    "        try:\n",
    "            if int(float(label)) == 1:\n",
    "                essential_genes.append(gene)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "essential_genes = sorted(set(essential_genes))\n",
    "essential_set = set(essential_genes)\n",
    "\n",
    "print(f\"Essential genes (label==1): n={len(essential_genes)}\")\n",
    "print(essential_genes)\n",
    "\n",
    "# ========== Step 2: Read combination CSV ==========\n",
    "df = pd.read_csv(combo_file, header=None)\n",
    "print(f\"\\nLoaded combos: shape={df.shape}\")\n",
    "\n",
    "# ========== Step 3: Filter rows that contain NO essential genes ==========\n",
    "keep_idx = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Filtering rows\"):\n",
    "    genes_in_row = set()\n",
    "\n",
    "    for x in row.values:\n",
    "        if pd.isna(x):\n",
    "            continue\n",
    "        s = str(x).strip()\n",
    "        if not s or s.lower() == \"nan\":\n",
    "            continue\n",
    "        genes_in_row.add(s)\n",
    "\n",
    "    # keep the row if it has at least one overlap with essential genes\n",
    "    if not genes_in_row.isdisjoint(essential_set):\n",
    "        keep_idx.append(idx)\n",
    "\n",
    "essential_df = df.loc[keep_idx].reset_index(drop=True)\n",
    "print(f\"Rows with essential genes: {len(essential_df)}\")\n",
    "\n",
    "# ========== Step 4: Write output ==========\n",
    "os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "essential_df.to_csv(out_file, header=False, index=False)\n",
    "print(f\"Saved: {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33d0740-0542-42b7-ada5-1159d6047c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total rows: 380719699\n",
      " number of 0: 380596069\n",
      " number of 1: 123630\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "file_path = '/data1/xpgeng/cross_pathogen/FBA/iML1515_all_non_essential.csv'\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(file_path, header=None)  # 如果没有表头，使用 header=None\n",
    "\n",
    "# 获取最后一列的列名\n",
    "last_column = df.columns[-1]\n",
    "\n",
    "# 计算最后一列中0和1的数量\n",
    "count_zeros = (df[last_column] == 0).sum()\n",
    "count_ones = (df[last_column] == 1).sum()\n",
    "\n",
    "# 计算总行数\n",
    "total_rows = len(df)\n",
    "\n",
    "print(f\" total rows: {total_rows}\")\n",
    "print(f\" number of 0: {count_zeros}\")\n",
    "print(f\" number of 1: {count_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ad70da-ac0c-4b8f-856d-bd50483679eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1      2  3\n",
      "0  b0033  b0036  b0037  0\n",
      "1  b0033  b0036  b0038  0\n",
      "2  b0033  b0036  b0040  0\n",
      "3  b0033  b0036  b0046  0\n",
      "4  b0033  b0036  b0047  0\n",
      "5  b0033  b0036  b0048  0\n",
      "6  b0033  b0036  b0049  0\n",
      "7  b0033  b0036  b0061  0\n",
      "8  b0033  b0036  b0062  0\n",
      "9  b0033  b0036  b0063  0\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7304711e-2d91-4b23-930c-e7f7b7a632ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total rows: 195387920\n",
      " number of 0: 0\n",
      " number of 1: 195387920\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "file_path = '/data1/xpgeng/cross_pathogen/FBA/iML1515_all_with-essential.csv'\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(file_path, header=None)  # 如果没有表头，使用 header=None\n",
    "\n",
    "# 获取最后一列的列名\n",
    "last_column = df.columns[-1]\n",
    "\n",
    "# 计算最后一列中0和1的数量\n",
    "count_zeros = (df[last_column] == 0).sum()\n",
    "count_ones = (df[last_column] == 1).sum()\n",
    "\n",
    "# 计算总行数\n",
    "total_rows = len(df)\n",
    "\n",
    "print(f\" total rows: {total_rows}\")\n",
    "print(f\" number of 0: {count_zeros}\")\n",
    "print(f\" number of 1: {count_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374759e-bff8-474b-b3f7-5516f6ffe178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c52401e-010e-4218-9d9f-c791fbfe664b",
   "metadata": {},
   "source": [
    "## Part-2 we use all the positive samples and same the negative samples to build no-essential triples dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a6b359-fe1d-40fa-8e8e-ecc6876812c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved sampled dataset: /data1/xpgeng/cross_pathogen/sci_rep_revision_20260113/Baseline/triples_no_essential_123630x2-0_123630-1.csv\n",
      "Shape: (370890, 4)\n",
      "Label counts:\n",
      " y\n",
      "0    247260\n",
      "1    123630\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 从刚才读取的文件里随机选择为0 的，所有label为1 的，作为不包含essential gene 的三基因组合subsampling\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ====== Input ======\n",
    "NONESSENTIAL_CSV = '/data1/xpgeng/cross_pathogen/FBA/iML1515_all_non_essential.csv'  # 4列，无表头: g1,g2,g3,y\n",
    "SEED = 42\n",
    "\n",
    "# ====== Output ======\n",
    "SAMPLED_CSV = '/data1/xpgeng/cross_pathogen/sci_rep_revision_20260113/Baseline/triples_no_essential_123630x2-0_123630-1.csv'\n",
    "\n",
    "# 读取：无表头，手动指定列名\n",
    "df = pd.read_csv(NONESSENTIAL_CSV, header=None, names=['g1','g2','g3','y'])\n",
    "\n",
    "# 保证 y 是 int\n",
    "df['y'] = df['y'].astype(int)\n",
    "\n",
    "# 抽样数量\n",
    "N1 = 123630\n",
    "N0 = 123630*2\n",
    "\n",
    "df0 = df[df['y'] == 0]\n",
    "df1 = df[df['y'] == 1]\n",
    "\n",
    "n0 = min(N0, len(df0))\n",
    "n1 = min(N1, len(df1))\n",
    "\n",
    "if n0 < N0:\n",
    "    print(f\"[WARN] y=0 only has {len(df0)} rows, sampling {n0}\")\n",
    "if n1 < N1:\n",
    "    print(f\"[WARN] y=1 only has {len(df1)} rows, sampling {n1}\")\n",
    "\n",
    "sample0 = df0.sample(n=n0, random_state=SEED, replace=False)\n",
    "sample1 = df1.sample(n=n1, random_state=SEED, replace=False)\n",
    "\n",
    "df_sample = pd.concat([sample0, sample1], axis=0).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# 保存：不写 index，不写表头（保持和原始格式一致）\n",
    "os.makedirs(os.path.dirname(SAMPLED_CSV), exist_ok=True)\n",
    "df_sample.to_csv(SAMPLED_CSV, index=False, header=False)\n",
    "\n",
    "print(\"✅ Saved sampled dataset:\", SAMPLED_CSV)\n",
    "print(\"Shape:\", df_sample.shape)\n",
    "print(\"Label counts:\\n\", df_sample['y'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778441da-cf8a-4e54-948f-77b28105865c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c43c6dd1-3d6b-46ba-85dc-3bb184f69e36",
   "metadata": {},
   "source": [
    "## Part-2 we extract 123630 positive samples to build with-essential triples dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3efadae8-04e7-4da8-8f87-43bd54e7743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved sampled dataset: /data1/xpgeng/cross_pathogen/sci_rep_revision_20260113/Baseline/triples_with_essential_0-0_123630-1.csv\n",
      "Shape: (123630, 4)\n",
      "Label counts:\n",
      " y\n",
      "1    123630\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 从刚才读取的文件里随机选择为0 的，所有label为1 的，作为不包含essential gene 的三基因组合subsampling\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ====== Input ======\n",
    "NONESSENTIAL_CSV = '/data1/xpgeng/cross_pathogen/FBA/iML1515_all_with-essential.csv'  # 4列，无表头: g1,g2,g3,y\n",
    "SEED = 42\n",
    "\n",
    "# ====== Output ======\n",
    "SAMPLED_CSV = '/data1/xpgeng/cross_pathogen/sci_rep_revision_20260113/Baseline/triples_with_essential_0-0_123630-1.csv'\n",
    "\n",
    "# 读取：无表头，手动指定列名\n",
    "df = pd.read_csv(NONESSENTIAL_CSV, header=None, names=['g1','g2','g3','y'])\n",
    "\n",
    "# 保证 y 是 int\n",
    "df['y'] = df['y'].astype(int)\n",
    "\n",
    "# 抽样数量\n",
    "N1 = 123630\n",
    "N0 = 0\n",
    "\n",
    "df0 = df[df['y'] == 0]\n",
    "df1 = df[df['y'] == 1]\n",
    "\n",
    "n0 = min(N0, len(df0))\n",
    "n1 = min(N1, len(df1))\n",
    "\n",
    "if n0 < N0:\n",
    "    print(f\"[WARN] y=0 only has {len(df0)} rows, sampling {n0}\")\n",
    "if n1 < N1:\n",
    "    print(f\"[WARN] y=1 only has {len(df1)} rows, sampling {n1}\")\n",
    "\n",
    "sample0 = df0.sample(n=n0, random_state=SEED, replace=False)\n",
    "sample1 = df1.sample(n=n1, random_state=SEED, replace=False)\n",
    "\n",
    "df_sample = pd.concat([sample0, sample1], axis=0).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# 保存：不写 index，不写表头（保持和原始格式一致）\n",
    "os.makedirs(os.path.dirname(SAMPLED_CSV), exist_ok=True)\n",
    "df_sample.to_csv(SAMPLED_CSV, index=False, header=False)\n",
    "\n",
    "print(\"✅ Saved sampled dataset:\", SAMPLED_CSV)\n",
    "print(\"Shape:\", df_sample.shape)\n",
    "print(\"Label counts:\\n\", df_sample['y'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45354521-9d4b-4825-947a-70dc1e60f7ca",
   "metadata": {},
   "source": [
    "## The following code is analyzing these new triples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e46d3a-1c16-4929-b506-d2e732931783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved sampled dataset: /data1/xpgeng/cross_pathogen/FBA/E.coli_K-12_MG1655_lethal_triple_no_individual_lethal_genes_123630_count_by_FBA_20260213_v.01.csv\n",
      "Shape: (123630, 4)\n",
      "Label counts:\n",
      " y\n",
      "1    123630\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 从刚才读取的文件里随机选择label为1 的，作为不包含essential gene 的三基因组合all\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ====== Input ======\n",
    "NONESSENTIAL_CSV = '/data1/xpgeng/cross_pathogen/FBA/iML1515_all_non-essential.csv'  # 4列，无表头: g1,g2,g3,y\n",
    "SEED = 42\n",
    "\n",
    "# ====== Output ======\n",
    "SAMPLED_CSV = '/data1/xpgeng/cross_pathogen/FBA/E.coli_K-12_MG1655_lethal_triple_no_individual_lethal_genes_123630_count_by_FBA_20260213_v.01.csv'\n",
    "\n",
    "# 读取：无表头，手动指定列名\n",
    "df = pd.read_csv(NONESSENTIAL_CSV, header=None, names=['g1','g2','g3','y'])\n",
    "\n",
    "# 保证 y 是 int\n",
    "df['y'] = df['y'].astype(int)\n",
    "\n",
    "# 抽样数量\n",
    "N0 = 0\n",
    "N1 = 123630\n",
    "\n",
    "df0 = df[df['y'] == 0]\n",
    "df1 = df[df['y'] == 1]\n",
    "\n",
    "n0 = min(N0, len(df0))\n",
    "n1 = min(N1, len(df1))\n",
    "\n",
    "if n0 < N0:\n",
    "    print(f\"[WARN] y=0 only has {len(df0)} rows, sampling {n0}\")\n",
    "if n1 < N1:\n",
    "    print(f\"[WARN] y=1 only has {len(df1)} rows, sampling {n1}\")\n",
    "\n",
    "sample0 = df0.sample(n=n0, random_state=SEED, replace=False)\n",
    "sample1 = df1.sample(n=n1, random_state=SEED, replace=False)\n",
    "\n",
    "df_sample = pd.concat([sample0, sample1], axis=0).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# 保存：不写 index，不写表头（保持和原始格式一致）\n",
    "os.makedirs(os.path.dirname(SAMPLED_CSV), exist_ok=True)\n",
    "df_sample.to_csv(SAMPLED_CSV, index=False, header=False)\n",
    "\n",
    "print(\"✅ Saved sampled dataset:\", SAMPLED_CSV)\n",
    "print(\"Shape:\", df_sample.shape)\n",
    "print(\"Label counts:\\n\", df_sample['y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4fc8bf-4c21-479b-962b-d0b58cfee4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总计行数: 123629\n",
      "涉及到的基因总数（去重后）: 1318\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 你的文件路径\n",
    "SAMPLED_CSV = '/data1/xpgeng/cross_pathogen/FBA/E.coli_K-12_MG1655_lethal_triple_no_individual_lethal_genes_123630_count_by_FBA_20260213_v.01.csv'\n",
    "\n",
    "# 读取数据\n",
    "# 假设前三列是基因，这里我们直接读取前三列\n",
    "df = pd.read_csv(SAMPLED_CSV)\n",
    "\n",
    "# 将前三列的所有值提取出来，并转换为一维序列\n",
    "# 假设你的列名分别是 'gene1', 'gene2', 'gene3' (或者根据索引提取)\n",
    "# 如果没有表头，可以加上 header=None\n",
    "all_genes = df.iloc[:, 0:3].values.flatten()\n",
    "\n",
    "# 转为集合去重\n",
    "unique_genes = set(all_genes)\n",
    "\n",
    "print(f\"总计行数: {len(df)}\")\n",
    "print(f\"涉及到的基因总数（去重后）: {len(unique_genes)}\")\n",
    "\n",
    "# 如果你想查看具体的基因列表，可以取消下面这一行的注释\n",
    "# print(list(unique_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8293d1-afe3-4959-8254-17aba9cb7ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出现频率最高的前 10 个基因对：\n",
      "          Gene_Pair  Frequency\n",
      "0    (b0078, b3671)       1316\n",
      "1    (b0048, b1606)       1316\n",
      "2    (b0763, b2424)       1316\n",
      "3    (b0077, b3671)       1316\n",
      "4    (b0002, b3940)       1316\n",
      "..              ...        ...\n",
      "195  (b2422, b2529)          9\n",
      "196  (b1592, b1779)          9\n",
      "197  (b2926, b2935)          9\n",
      "198  (b0763, b2529)          9\n",
      "199  (b2913, b2926)          9\n",
      "\n",
      "[200 rows x 2 columns]\n",
      "\n",
      "共有 54767 组对在不同行中重复出现。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "# 1. 读取数据\n",
    "SAMPLED_CSV = '/data1/xpgeng/cross_pathogen/FBA/E.coli_K-12_MG1655_lethal_triple_no_individual_lethal_genes_123630_count_by_FBA_20260213_v.01.csv'\n",
    "df = pd.read_csv(SAMPLED_CSV)\n",
    "\n",
    "# 2. 提取每行的基因对（无序组合）\n",
    "pair_counts = Counter()\n",
    "\n",
    "for _, row in df.iloc[:, 0:3].iterrows():\n",
    "    # 对每一行的 3 个基因进行排序并取两两组合，确保 (A, B) 和 (B, A) 被视为同一个对\n",
    "    genes = sorted(row.values)\n",
    "    pairs = list(combinations(genes, 2))\n",
    "    pair_counts.update(pairs)\n",
    "\n",
    "# 3. 转换为 DataFrame 方便分析\n",
    "pair_df = pd.DataFrame(pair_counts.items(), columns=['Gene_Pair', 'Frequency'])\n",
    "pair_df = pair_df.sort_values(by='Frequency', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 4. 输出结果\n",
    "print(\"出现频率最高的前 10 个基因对：\")\n",
    "print(pair_df.head(200))\n",
    "\n",
    "# 可选：筛选出出现次数大于 1 的“频繁对”\n",
    "frequent_pairs = pair_df[pair_df['Frequency'] > 1]\n",
    "print(f\"\\n共有 {len(frequent_pairs)} 组对在不同行中重复出现。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf4b8bb-4d16-4817-adbc-d706f9195aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取数据...\n",
      "正在提取基因对并进行统计...\n",
      "处理完成！\n",
      "总计发现出现次数 > 1 的基因对数量: 54767\n",
      "结果已保存至: /data1/xpgeng/cross_pathogen/FBA/E.coli_K-12-MG1655_lethal_new_triple_frequent_gene_pairs_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "# 1. 路径设置\n",
    "SAMPLED_CSV = '/data1/xpgeng/cross_pathogen/FBA/E.coli_K-12_MG1655_lethal_triple_no_individual_lethal_genes_123630_count_by_FBA_20260213_v.01.csv'\n",
    "OUTPUT_CSV = '/data1/xpgeng/cross_pathogen/FBA/E.coli_K-12-MG1655_lethal_new_triple_frequent_gene_pairs_analysis.csv'\n",
    "\n",
    "# 2. 读取并处理\n",
    "print(\"正在读取数据...\")\n",
    "df = pd.read_csv(SAMPLED_CSV)\n",
    "\n",
    "# 统计基因对频率\n",
    "pair_counts = Counter()\n",
    "\n",
    "print(\"正在提取基因对并进行统计...\")\n",
    "# 仅取前三列，并逐行处理\n",
    "for row in df.iloc[:, 0:3].values:\n",
    "    # 排序以保证无序性 (A,B) == (B,A)\n",
    "    genes = sorted(row)\n",
    "    # 生成 3 条 pairs: (G1,G2), (G1,G3), (G2,G3)\n",
    "    pairs = combinations(genes, 2)\n",
    "    pair_counts.update(pairs)\n",
    "\n",
    "# 3. 转换为 DataFrame\n",
    "# 将元组 (GeneA, GeneB) 拆分为两列，方便后续分析\n",
    "pair_data = []\n",
    "for (g1, g2), freq in pair_counts.items():\n",
    "    if freq > 1:  # 核心逻辑：过滤掉只出现 1 次的\n",
    "        pair_data.append([g1, g2, freq])\n",
    "\n",
    "result_df = pd.DataFrame(pair_data, columns=['Gene_A', 'Gene_B', 'Frequency'])\n",
    "\n",
    "# 4. 排序并保存\n",
    "result_df = result_df.sort_values(by='Frequency', ascending=False)\n",
    "result_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"处理完成！\")\n",
    "print(f\"总计发现出现次数 > 1 的基因对数量: {len(result_df)}\")\n",
    "print(f\"结果已保存至: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df223d8-fb4f-4578-9cfc-59277c450963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorchh] *",
   "language": "python",
   "name": "conda-env-.conda-pytorchh-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
