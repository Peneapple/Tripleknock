[2026-02-15 15:43:37] Config loaded.
[2026-02-15 15:44:09] two_mer_dict & ae1_2 ready.
[2026-02-15 15:45:55] Reading CSV parts (streaming) and building pair-disjoint pools...
[2026-02-15 15:45:55] File: /data1/xpgeng/cross_pathogen/FBA/iML1515_parts/iML1515-1.csv
[2026-02-15 15:45:59]   chunk=5 | kept=40,301 dropped=959,699 | pool_sizes=[7975, 8166, 8017, 8075, 8068]
[2026-02-15 15:46:03]   chunk=10 | kept=80,126 dropped=1,919,874 | pool_sizes=[15962, 16241, 15987, 15958, 15978]
[2026-02-15 15:46:06]   chunk=15 | kept=119,709 dropped=2,880,291 | pool_sizes=[23889, 24216, 23936, 23764, 23904]
[2026-02-15 15:46:09]   chunk=20 | kept=159,653 dropped=3,840,347 | pool_sizes=[31785, 32450, 31881, 31607, 31930]
[2026-02-15 15:46:12]   chunk=25 | kept=199,725 dropped=4,800,275 | pool_sizes=[39711, 40559, 39897, 39564, 39994]
[2026-02-15 15:46:16]   chunk=30 | kept=239,780 dropped=5,760,220 | pool_sizes=[47631, 48583, 47849, 47653, 48064]
[2026-02-15 15:46:19]   chunk=35 | kept=279,996 dropped=6,720,004 | pool_sizes=[55447, 56712, 56076, 55677, 56084]
[2026-02-15 15:46:22]   chunk=40 | kept=320,092 dropped=7,679,908 | pool_sizes=[63492, 64799, 64161, 63643, 63997]
[2026-02-15 15:46:26]   chunk=45 | kept=360,141 dropped=8,639,859 | pool_sizes=[71483, 72837, 72137, 71684, 72000]
[2026-02-15 15:46:29]   chunk=50 | kept=400,187 dropped=9,599,813 | pool_sizes=[79447, 81076, 80070, 79689, 79905]
[2026-02-15 15:46:33]   chunk=55 | kept=439,966 dropped=10,560,034 | pool_sizes=[87316, 89072, 87981, 87622, 87975]
[2026-02-15 15:46:37]   chunk=60 | kept=480,106 dropped=11,519,894 | pool_sizes=[95156, 97122, 96038, 95694, 96096]
[2026-02-15 15:46:40]   chunk=65 | kept=520,156 dropped=12,479,844 | pool_sizes=[103041, 105133, 104071, 103677, 104234]
[2026-02-15 15:46:43]   chunk=70 | kept=560,160 dropped=13,439,840 | pool_sizes=[110905, 113241, 112050, 111645, 112319]
[2026-02-15 15:46:47]   chunk=75 | kept=600,375 dropped=14,399,625 | pool_sizes=[118812, 121418, 120261, 119532, 120352]
[2026-02-15 15:46:50]   chunk=80 | kept=640,246 dropped=15,359,754 | pool_sizes=[126661, 129667, 128183, 127346, 128389]
[2026-02-15 15:46:53]   chunk=85 | kept=680,045 dropped=16,319,955 | pool_sizes=[134468, 137755, 136084, 135314, 136424]
[2026-02-15 15:46:57]   chunk=90 | kept=720,156 dropped=17,279,844 | pool_sizes=[142446, 145909, 144136, 143281, 144384]
[2026-02-15 15:47:01]   chunk=95 | kept=760,087 dropped=18,239,913 | pool_sizes=[150351, 154020, 152101, 151222, 152393]
[2026-02-15 15:47:05]   chunk=100 | kept=800,259 dropped=19,199,741 | pool_sizes=[158226, 162055, 160229, 159420, 160329]
[2026-02-15 15:47:08]   chunk=105 | kept=840,479 dropped=20,159,521 | pool_sizes=[166178, 170126, 168397, 167378, 168400]
[2026-02-15 15:47:12]   chunk=110 | kept=880,644 dropped=21,119,356 | pool_sizes=[174127, 178265, 176505, 175285, 176462]
[2026-02-15 15:47:15]   chunk=115 | kept=920,814 dropped=22,079,186 | pool_sizes=[182124, 186377, 184602, 183273, 184438]
[2026-02-15 15:47:19]   chunk=120 | kept=961,057 dropped=23,038,943 | pool_sizes=[190216, 194468, 192644, 191227, 192502]
[2026-02-15 15:47:22]   chunk=125 | kept=1,000,910 dropped=23,999,090 | pool_sizes=[198107, 202556, 200649, 199148, 200450]
[2026-02-15 15:47:25]   chunk=130 | kept=1,041,463 dropped=24,958,537 | pool_sizes=[206164, 210768, 208662, 207212, 208657]
[2026-02-15 15:47:28]   chunk=135 | kept=1,081,604 dropped=25,918,396 | pool_sizes=[213964, 218814, 216713, 215343, 216770]
[2026-02-15 15:47:31]   chunk=140 | kept=1,121,647 dropped=26,878,353 | pool_sizes=[221823, 226920, 224748, 223464, 224692]
[2026-02-15 15:47:34]   chunk=145 | kept=1,161,896 dropped=27,838,104 | pool_sizes=[229830, 234995, 232837, 231521, 232713]
[2026-02-15 15:47:37]   chunk=150 | kept=1,201,595 dropped=28,798,405 | pool_sizes=[237673, 242999, 240673, 239586, 240664]
[2026-02-15 15:47:40]   chunk=155 | kept=1,241,741 dropped=29,758,259 | pool_sizes=[245644, 251019, 248794, 247546, 248738]
[2026-02-15 15:47:43]   chunk=160 | kept=1,281,759 dropped=30,718,241 | pool_sizes=[253671, 259072, 256659, 255526, 256831]
[2026-02-15 15:47:46]   chunk=165 | kept=1,321,667 dropped=31,678,333 | pool_sizes=[261570, 267121, 264602, 263537, 264837]
[2026-02-15 15:47:49]   chunk=170 | kept=1,361,258 dropped=32,638,742 | pool_sizes=[269406, 275203, 272529, 271368, 272752]
[2026-02-15 15:47:52]   chunk=175 | kept=1,401,322 dropped=33,598,678 | pool_sizes=[277331, 283340, 280511, 279408, 280732]
[2026-02-15 15:47:55]   chunk=180 | kept=1,441,415 dropped=34,558,585 | pool_sizes=[285330, 291381, 288555, 287370, 288779]
[2026-02-15 15:47:58]   chunk=185 | kept=1,481,436 dropped=35,518,564 | pool_sizes=[293358, 299368, 296455, 295376, 296879]
[2026-02-15 15:48:01]   chunk=190 | kept=1,521,733 dropped=36,478,267 | pool_sizes=[301259, 307470, 304408, 303564, 305032]
[2026-02-15 15:48:04]   chunk=195 | kept=1,561,792 dropped=37,438,208 | pool_sizes=[309173, 315486, 312400, 311660, 313073]
[2026-02-15 15:48:06]   chunk=200 | kept=1,601,536 dropped=38,398,464 | pool_sizes=[317058, 323544, 320349, 319479, 321106]
[2026-02-15 15:48:09]   chunk=205 | kept=1,641,373 dropped=39,358,627 | pool_sizes=[324810, 331633, 328377, 327355, 329198]
[2026-02-15 15:48:12]   chunk=210 | kept=1,681,290 dropped=40,318,710 | pool_sizes=[332681, 339699, 336525, 335243, 337142]
[2026-02-15 15:48:15]   chunk=215 | kept=1,721,080 dropped=41,278,920 | pool_sizes=[340465, 347840, 344611, 343152, 345012]
[2026-02-15 15:48:18]   chunk=220 | kept=1,761,029 dropped=42,238,971 | pool_sizes=[348483, 355861, 352529, 351075, 353081]
[2026-02-15 15:48:22]   chunk=225 | kept=1,800,837 dropped=43,199,163 | pool_sizes=[356161, 364000, 360502, 359121, 361053]
[2026-02-15 15:48:25]   chunk=230 | kept=1,840,622 dropped=44,159,378 | pool_sizes=[363980, 372007, 368385, 367255, 368995]
[2026-02-15 15:48:28]   chunk=235 | kept=1,880,454 dropped=45,119,546 | pool_sizes=[371854, 380047, 376341, 375236, 376976]
[2026-02-15 15:48:31]   chunk=240 | kept=1,920,878 dropped=46,079,122 | pool_sizes=[379898, 388277, 384518, 383235, 384950]
[2026-02-15 15:48:34]   chunk=245 | kept=1,960,923 dropped=47,039,077 | pool_sizes=[387805, 396377, 392522, 391288, 392931]
[2026-02-15 15:48:36]   chunk=250 | kept=1,994,882 dropped=47,999,118 | pool_sizes=[395756, 400000, 400000, 399126, 400000]
[2026-02-15 15:48:38] All fold pools reached target, stop reading more data.
[2026-02-15 15:48:39] Pair-disjoint pools built. kept=2,000,000, dropped=48,511,957
[2026-02-15 15:48:39] Final fold pool sizes: [400000, 400000, 400000, 400000, 400000]
[2026-02-15 15:48:39] [FoldPool 0] y=1 ratio = 0.3378
[2026-02-15 15:48:39] [FoldPool 1] y=1 ratio = 0.3410
[2026-02-15 15:48:39] [FoldPool 2] y=1 ratio = 0.3389
[2026-02-15 15:48:39] [FoldPool 3] y=1 ratio = 0.3391
[2026-02-15 15:48:39] [FoldPool 4] y=1 ratio = 0.3407
[2026-02-15 15:49:30] 
================== Pair Fold 0 ==================
[2026-02-15 15:49:30] Train pool=1,600,000 | Test pool=400,000
[2026-02-15 15:49:31] Train=1,440,000, Val=160,000, Test=400,000
[2026-02-15 15:49:31] y_train mean=0.3399, y_val mean=0.3399, y_test mean=0.3378
[2026-02-15 22:50:01] [Fold 0] Epoch 1: train_loss=0.138851, val_loss=0.014588, val_auc=0.999550
[2026-02-16 03:54:54] [Fold 0] Epoch 2: train_loss=0.041678, val_loss=0.006690, val_auc=0.999759
[2026-02-16 08:58:42] [Fold 0] Epoch 3: train_loss=0.029068, val_loss=0.004244, val_auc=0.999833
[2026-02-16 14:05:29] [Fold 0] Epoch 4: train_loss=0.023373, val_loss=0.004238, val_auc=0.999868
[2026-02-16 14:05:29] [Fold 0] Early stop at epoch 4 (best_val_auc=0.999550 @epoch 1)
[2026-02-16 14:05:32] [Fold 0] Best threshold from VAL = 0.425 | metric=youden
[2026-02-16 14:05:32] [Fold 0] VAL best stats = {'threshold': 0.4249999999999998, 'score': 0.9926501737626705, 'f1_pos': 0.9956536952793394, 'precision_pos': 0.997251531026341, 'recall_pos': 0.9940609715735668, 'tn': 105465, 'fp': 149, 'fn': 323, 'tp': 54063}
[2026-02-16 14:05:37] [Fold 0] ✅ TEST AUC = 0.999385
[2026-02-16 14:05:37] [Fold 0] TEST loss = 0.016738
[2026-02-16 14:05:37] [Fold 0] Confusion Matrix [[TN,FP],[FN,TP]]:
[[264426    464]
 [  1059 134051]]
[2026-02-16 14:05:37] [Fold 0] Report:
              precision    recall  f1-score   support

           0     0.9960    0.9982    0.9971    264890
           1     0.9966    0.9922    0.9944    135110

    accuracy                         0.9962    400000
   macro avg     0.9963    0.9952    0.9957    400000
weighted avg     0.9962    0.9962    0.9962    400000

[2026-02-16 14:05:39] 
================== Pair Fold 1 ==================
[2026-02-16 14:05:39] Train pool=1,600,000 | Test pool=400,000
[2026-02-16 14:05:41] Train=1,440,000, Val=160,000, Test=400,000
[2026-02-16 14:05:41] y_train mean=0.3391, y_val mean=0.3391, y_test mean=0.3410
[2026-02-16 21:06:53] [Fold 1] Epoch 1: train_loss=0.137663, val_loss=0.020007, val_auc=0.999278
[2026-02-17 02:26:54] [Fold 1] Epoch 2: train_loss=0.046562, val_loss=0.007733, val_auc=0.999699
[2026-02-17 07:41:13] [Fold 1] Epoch 3: train_loss=0.034830, val_loss=0.005876, val_auc=0.999720
[2026-02-17 12:52:52] [Fold 1] Epoch 4: train_loss=0.023639, val_loss=0.004229, val_auc=0.999818
[2026-02-17 17:59:03] [Fold 1] Epoch 5: train_loss=0.018785, val_loss=0.003344, val_auc=0.999857
[2026-02-17 23:06:42] [Fold 1] Epoch 6: train_loss=0.016854, val_loss=0.003290, val_auc=0.999814
[2026-02-18 04:12:26] [Fold 1] Epoch 7: train_loss=0.014236, val_loss=0.003068, val_auc=0.999834
[2026-02-18 04:12:26] [Fold 1] Early stop at epoch 7 (best_val_auc=0.999818 @epoch 4)
[2026-02-18 04:12:28] [Fold 1] Best threshold from VAL = 0.265 | metric=youden
[2026-02-18 04:12:28] [Fold 1] VAL best stats = {'threshold': 0.2649999999999999, 'score': 0.9980495425414071, 'f1_pos': 0.9989119209201255, 'precision_pos': 0.9995386602694224, 'recall_pos': 0.9982859670463342, 'tn': 105717, 'fp': 25, 'fn': 93, 'tp': 54165}
[2026-02-18 04:12:32] [Fold 1] ✅ TEST AUC = 0.999835
[2026-02-18 04:12:32] [Fold 1] TEST loss = 0.003997
[2026-02-18 04:12:32] [Fold 1] Confusion Matrix [[TN,FP],[FN,TP]]:
[[263522     86]
 [   210 136182]]
[2026-02-18 04:12:32] [Fold 1] Report:
              precision    recall  f1-score   support

           0     0.9992    0.9997    0.9994    263608
           1     0.9994    0.9985    0.9989    136392

    accuracy                         0.9993    400000
   macro avg     0.9993    0.9991    0.9992    400000
weighted avg     0.9993    0.9993    0.9993    400000

[2026-02-18 04:12:33] 
================== Pair Fold 2 ==================
[2026-02-18 04:12:33] Train pool=1,600,000 | Test pool=400,000
[2026-02-18 04:12:35] Train=1,440,000, Val=160,000, Test=400,000
[2026-02-18 04:12:35] y_train mean=0.3396, y_val mean=0.3396, y_test mean=0.3389
[2026-02-18 11:11:10] [Fold 2] Epoch 1: train_loss=0.164043, val_loss=0.023049, val_auc=0.999256
[2026-02-18 16:16:44] [Fold 2] Epoch 2: train_loss=0.054334, val_loss=0.009545, val_auc=0.999608
[2026-02-18 21:20:33] [Fold 2] Epoch 3: train_loss=0.040981, val_loss=0.008664, val_auc=0.999598
[2026-02-19 02:35:19] [Fold 2] Epoch 4: train_loss=0.035034, val_loss=0.007229, val_auc=0.999720
[2026-02-19 02:35:19] [Fold 2] Early stop at epoch 4 (best_val_auc=0.999256 @epoch 1)
[2026-02-19 02:35:22] [Fold 2] Best threshold from VAL = 0.365 | metric=youden
[2026-02-19 02:35:22] [Fold 2] VAL best stats = {'threshold': 0.3649999999999998, 'score': 0.987720134254699, 'f1_pos': 0.9920461031423939, 'precision_pos': 0.9925395129499318, 'recall_pos': 0.9915531836584468, 'tn': 105255, 'fp': 405, 'fn': 459, 'tp': 53881}
[2026-02-19 02:35:25] [Fold 2] ✅ TEST AUC = 0.999343
[2026-02-19 02:35:25] [Fold 2] TEST loss = 0.023264
[2026-02-19 02:35:25] [Fold 2] Confusion Matrix [[TN,FP],[FN,TP]]:
[[263276   1157]
 [  1068 134499]]
[2026-02-19 02:35:25] [Fold 2] Report:
              precision    recall  f1-score   support

           0     0.9960    0.9956    0.9958    264433
           1     0.9915    0.9921    0.9918    135567

    accuracy                         0.9944    400000
   macro avg     0.9937    0.9939    0.9938    400000
weighted avg     0.9944    0.9944    0.9944    400000

[2026-02-19 02:35:26] 
================== Pair Fold 3 ==================
[2026-02-19 02:35:26] Train pool=1,600,000 | Test pool=400,000
[2026-02-19 02:35:27] Train=1,440,000, Val=160,000, Test=400,000
[2026-02-19 02:35:27] y_train mean=0.3396, y_val mean=0.3396, y_test mean=0.3391
[2026-02-19 09:33:48] [Fold 3] Epoch 1: train_loss=0.151944, val_loss=0.017281, val_auc=0.999240
[2026-02-19 16:22:36] [Fold 3] Epoch 2: train_loss=0.051705, val_loss=0.009245, val_auc=0.999653
[2026-02-19 23:49:14] [Fold 3] Epoch 3: train_loss=0.039129, val_loss=0.006253, val_auc=0.999771
[2026-02-20 06:53:13] [Fold 3] Epoch 4: train_loss=0.032643, val_loss=0.005484, val_auc=0.999813
[2026-02-20 11:58:43] [Fold 3] Epoch 5: train_loss=0.024348, val_loss=0.004314, val_auc=0.999829
[2026-02-20 17:05:00] [Fold 3] Epoch 6: train_loss=0.023922, val_loss=0.003675, val_auc=0.999871
[2026-02-20 17:05:00] [Fold 3] Early stop at epoch 6 (best_val_auc=0.999771 @epoch 3)
[2026-02-20 17:05:03] [Fold 3] Best threshold from VAL = 0.460 | metric=youden
[2026-02-20 17:05:03] [Fold 3] VAL best stats = {'threshold': 0.4599999999999998, 'score': 0.9968997385791603, 'f1_pos': 0.9981492223966713, 'precision_pos': 0.9987653865998378, 'recall_pos': 0.9975338179810436, 'tn': 105598, 'fp': 67, 'fn': 134, 'tp': 54201}
[2026-02-20 17:05:07] [Fold 3] ✅ TEST AUC = 0.999628
[2026-02-20 17:05:07] [Fold 3] TEST loss = 0.007605
[2026-02-20 17:05:07] [Fold 3] Confusion Matrix [[TN,FP],[FN,TP]]:
[[264129    245]
 [   401 135225]]
[2026-02-20 17:05:07] [Fold 3] Report:
              precision    recall  f1-score   support

           0     0.9985    0.9991    0.9988    264374
           1     0.9982    0.9970    0.9976    135626

    accuracy                         0.9984    400000
   macro avg     0.9983    0.9981    0.9982    400000
weighted avg     0.9984    0.9984    0.9984    400000

[2026-02-20 17:05:08] 
================== Pair Fold 4 ==================
[2026-02-20 17:05:08] Train pool=1,600,000 | Test pool=400,000
[2026-02-20 17:05:10] Train=1,440,000, Val=160,000, Test=400,000
[2026-02-20 17:05:10] y_train mean=0.3392, y_val mean=0.3392, y_test mean=0.3407
[2026-02-20 23:44:47] [Fold 4] Epoch 1: train_loss=0.167176, val_loss=0.023821, val_auc=0.999167
[2026-02-21 04:47:20] [Fold 4] Epoch 2: train_loss=0.057881, val_loss=0.010759, val_auc=0.999657
[2026-02-21 09:30:49] [Fold 4] Epoch 3: train_loss=0.043317, val_loss=0.008285, val_auc=0.999676
[2026-02-21 14:36:49] [Fold 4] Epoch 4: train_loss=0.036157, val_loss=0.005798, val_auc=0.999737
[2026-02-21 21:09:26] [Fold 4] Epoch 5: train_loss=0.031464, val_loss=0.005488, val_auc=0.999763
[2026-02-22 03:37:42] [Fold 4] Epoch 6: train_loss=0.026085, val_loss=0.004384, val_auc=0.999802
[2026-02-22 03:37:42] [Fold 4] Early stop at epoch 6 (best_val_auc=0.999676 @epoch 3)
[2026-02-22 03:37:47] [Fold 4] Best threshold from VAL = 0.300 | metric=youden
[2026-02-22 03:37:47] [Fold 4] VAL best stats = {'threshold': 0.2999999999999999, 'score': 0.9958212517461105, 'f1_pos': 0.9973091525668633, 'precision_pos': 0.9975297717804078, 'recall_pos': 0.9970886309194766, 'tn': 105596, 'fp': 134, 'fn': 158, 'tp': 54112}
[2026-02-22 03:37:50] [Fold 4] ✅ TEST AUC = 0.999633
[2026-02-22 03:37:50] [Fold 4] TEST loss = 0.009262
[2026-02-22 03:37:50] [Fold 4] Confusion Matrix [[TN,FP],[FN,TP]]:
[[263319    405]
 [   447 135829]]
[2026-02-22 03:37:50] [Fold 4] Report:
              precision    recall  f1-score   support

           0     0.9983    0.9985    0.9984    263724
           1     0.9970    0.9967    0.9969    136276

    accuracy                         0.9979    400000
   macro avg     0.9977    0.9976    0.9976    400000
weighted avg     0.9979    0.9979    0.9979    400000

[2026-02-22 03:37:52] 
==================== Pair-disjoint CV Summary ====================
[2026-02-22 03:37:52] AUCs per fold: [0.9993849877214237, 0.9998346517270182, 0.999342677105478, 0.9996281137350369, 0.9996327154759745]
[2026-02-22 03:37:52] Mean AUC = 0.999565, Std = 0.000181
